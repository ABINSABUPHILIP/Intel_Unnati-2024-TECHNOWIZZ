# PROBLEM STATEMENT 16:
# Running GenAI on Intel AI Laptops and Simple LLM Inference on CPU and fine-tuning of LLM Models using Intel® OpenVINO™
## Category:
Artificial Intelligence, Machine Learning, LLM, NLP
## Participants:
5th-8th Semester Students
## Pre-requisite:
- Understanding of Machine Learning Concepts.
- Programming skills (Python, NLP libraries like Hugging Face, transformers).
- Experience with natural language processing (NLP) and text-based AI models (e.g., language models, Chatbots).
## Description:
This problem statement is designed to introduce beginners to the exciting field of Generative Artificial Intelligence (GenAI) through a series of hands-on exercises. Participants will learn the basics of GenAI, perform simple Large Language Model (LLM) inference on a CPU, and explore the process of fine-tuning an LLM model to create a custom Chatbot.
## Major Challenges:
1. Pre-trained language models can have large file sizes, which may require significant storage space and memory to load and run.
2. Learn LLM inference on CPU.
3. Understanding the concept of fine-tuning and its importance in customizing LLMs.
4. Create a Custom Chatbot with Fine-tuned Pre-trained Large Language Models (LLMs) using Intel AI Tools.

## Outcomes:
1. Participants will gain a foundational understanding of Generative AI and its applications.
2. Participants will be able to perform simple LLM inference on a CPU and understand the process of fine-tuning LLMs for custom applications.
3. Create a 5-page report on Problem, Technical approach and results.

## Setup and Installation:

### Prerequisites

- Python 3 or higher
- Intel® OpenVINO™ toolkit
- Hugging Face transformers library
- Other dependencies listed in `requirements.txt`

### Installation

1. Clone the repository:
    ```sh
    git clone https://github.com/23Jyo/SiliconSquad.git
    cd <repository-directory>
    ```

2. Create a virtual environment:
    ```sh
    python -m venv myenv
    .\myenv\Scripts\Activate.ps1  # to activate the environment
    ```

3. Install dependencies:
    ```sh
    pip install -r requirements.txt
    ```

4. Install Intel® OpenVINO™ toolkit:
    Follow the instructions at [Intel OpenVINO Installation Guide](https://docs.openvino.ai/latest/openvino_docs_install_guides_installing_openvino.html)

### Steps taken to create the chatbot.





## Usage

## Libraries used 
-`Transformers:` For using pre-trained models and performing inference.

-`OpenVINO:` For optimizing and accelerating the model on Intel hardware.

-`Optimum Intel:` For integrating Hugging Face models with OpenVINO.

-`ONNX:` For exporting models to the ONNX format.

-`Numpy:` For numerical operations.

-`Torch:` PyTorch for deep learning models.

-`Streamlit:` is a Python library that allows you to create interactive, web-based applications for data science and machine learning projects.

-`onnxruntime:` is a high performance inference engine for running machine learning models in the ONNX format.

## Team Members

-   [Abin Sabu Philip](https://github.com/ABINSABUPHILIP)

-   [Abhinand M](https://github.com/aiswaryarahull)
